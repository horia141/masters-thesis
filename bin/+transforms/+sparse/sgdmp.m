classdef sgdmp < transforms.reversible
    properties (GetAccess=public,SetAccess=immutable)
        sparse_dict;
        word_count;
        coeffs_count;
        initial_learning_rate;
        final_learning_rate;
        max_iter_count;
    end
    
    properties (GetAccess=public,SetAccess=immutable)
        one_sample_plain;
        one_sample_coded;
    end
    
    methods (Access=public)
        function [obj] = sgdmp(train_dataset_plain,word_count,coeffs_count,initial_learning_rate,final_learning_rate,max_iter_count,logger)
            assert(tc.scalar(train_dataset_plain));
            assert(tc.dataset(train_dataset_plain));
            assert(train_dataset_plain.samples_count >= 1);
            assert(tc.scalar(word_count));
            assert(tc.natural(word_count));
            assert(word_count >= 1);
            assert(tc.scalar(coeffs_count));
            assert(tc.natural(coeffs_count));
            assert(coeffs_count >= 1 && coeffs_count <= word_count);
            assert(tc.scalar(initial_learning_rate));
            assert(tc.number(initial_learning_rate));
            assert(initial_learning_rate > 0);
            assert(tc.scalar(final_learning_rate));
            assert(tc.number(final_learning_rate));
            assert(final_learning_rate > 0);
            assert(final_learning_rate <= initial_learning_rate);
            assert(tc.scalar(max_iter_count));
            assert(tc.natural(max_iter_count));
            assert(max_iter_count >= 1);
            assert(tc.scalar(logger));
            assert(tc.logging_logger(logger));
            assert(logger.active);
            
            logger.beg_node('Learning sparse dictionary');
            
            initial_dict = rand(train_dataset_plain.features_count,word_count);
            sparse_dict_t = transforms.sparse.sgdmp.dict_gradient_descent(initial_dict,train_dataset_plain.samples,coeffs_count,...
                                                                          initial_learning_rate,final_learning_rate,max_iter_count,logger);
                                                                      
            logger.end_node();
            
            obj = obj@transforms.reversible(logger);
            obj.sparse_dict = sparse_dict_t;
            obj.word_count = word_count;
            obj.coeffs_count = coeffs_count;
            obj.initial_learning_rate = initial_learning_rate;
            obj.final_learning_rate = final_learning_rate;
            obj.max_iter_count = max_iter_count;
            
            logger.beg_node('Extracting plain/coded samples');
            
            obj.one_sample_plain = train_dataset_plain.subsamples(1);
            obj.one_sample_coded = obj.do_code(obj.one_sample_plain,logger);
            
            logger.end_node();
        end
    end
    
    methods (Access=protected)
        function [dataset_coded] = do_code(obj,dataset_plain,logger)
            log_batch_size = ceil(dataset_plain.samples_count / 10);
            samples_coded = zeros(dataset_plain.samples_count,obj.word_count);
            
            logger.beg_node('Building sparse samples');
            
            for ii = 1:dataset_plain.samples_count
                if mod(ii-1,log_batch_size) == 0
                    logger.message('Processing samples %d to %d.',ii,min(ii+log_batch_size-1,dataset_plain.samples_count));
                end

                samples_coded(ii,:) = transforms.sparse.sgdmp.matching_pursuit(obj.sparse_dict,dataset_plain.samples(ii,:),obj.coeffs_count)';
            end
            
            logger.end_node();
            
            logger.message('Building dataset.');
            
            dataset_coded = dataset(dataset_plain.classes,samples_coded,dataset_plain.labels_idx);
        end
        
        function [dataset_plain_hat] = do_decode(obj,dataset_coded,logger)
            log_batch_size = ceil(dataset_coded.samples_count / 10);
            samples_plain_hat = zeros(dataset_coded.samples_count,obj.one_sample_plain.features_count);
            
            logger.beg_node('Restoring original samples from sparse ones');
            
            for ii = 1:dataset_coded.samples_count
                if mod(ii-1,log_batch_size) == 0
                    logger.message('Processing samples %d to %d.',ii,min(ii+log_batch_size-1,dataset_coded.samples_count));
                end

                samples_plain_hat(ii,:) = obj.sparse_dict * dataset_coded.samples(ii,:)';
            end
            
            logger.end_node();
            
            logger.message('Building dataset.');
            
            dataset_plain_hat = dataset(dataset_coded.classes,samples_plain_hat,dataset_coded.labels_idx);
        end
    end
    
    methods (Static,Access=public)
        function [norm_dict] = normalize_dict(dict)
            norm_dict = dict ./ repmat(sqrt(sum(dict .^ 2,1)),size(dict,1),1);
        end
        
        function [dict] = dict_gradient_descent(initial_dict,samples,coeffs_count,initial_learning_rate,final_learning_rate,max_iter_count,logger)
            logger.message('Building initial dictionary.');
            
            log_batch_size = ceil(max_iter_count / 20);
            dict = transforms.sparse.sgdmp.normalize_dict(initial_dict);
            
            logger.beg_node('Tracking progress');
            
            for iter = 1:max_iter_count
                if mod(iter-1,log_batch_size) == 0
                    logger.message('Iterations %d to %d.',iter,iter + log_batch_size - 1);
                end

                c_sample = samples(randi(size(samples,1)),:);
                c_coeffs = transforms.sparse.sgdmp.matching_pursuit(dict,c_sample,coeffs_count);
                
                delta_dict = (c_sample' - dict * c_coeffs) * c_coeffs';
                learning_rate = initial_learning_rate * (final_learning_rate / initial_learning_rate) ^ (iter / max_iter_count);
                
                dict = dict + learning_rate * delta_dict;
                dict = transforms.sparse.sgdmp.normalize_dict(dict);
            end
            
            logger.end_node();
        end
        
        function [coeffs] = matching_pursuit(dict,sample,coeffs_count)
            coeffs = zeros(size(dict,2),1);
            sample_approx = sample;
            
            for k = 1:coeffs_count
                similarities = (sample_approx * dict) .^ 2;
                [~,best_match] = max(similarities);
                coeffs(best_match) = sample_approx * dict(:,best_match);
                sample_approx = sample_approx - coeffs(best_match) * dict(:,best_match)';
            end
        end
    end
    
    methods (Static,Access=public)
        function test(display)
            fprintf('Testing "transforms.sparse.sgdmp".\n');
            
            fprintf('  Proper construction.\n');
            
            hnd = logging.handlers.testing(logging.level.All);
            log = logging.logger({hnd});
            A = [mvnrnd([0 0],[3 0; 0 0.01],200);mvnrnd([0 0],[0.01 0; 0 3],200);mvnrnd([0 0],[2 1.95; 1.95 2],200)];
            c = ones(600,1);            
            s = dataset({'none'},A,c);
            
            t = transforms.sparse.sgdmp(s,4,1,0.1,0.01,1000,log);
            
            assert(tc.check(size(t.sparse_dict) == [2 4]));
            assert(tc.matrix(t.sparse_dict) && tc.unitreal(abs(t.sparse_dict)));
            assert(tc.check(arrayfun(@(ii)tc.same(norm(t.sparse_dict(:,ii)),1),1:4)));
            assert(tc.same(abs(t.sparse_dict(:,1)),[1;0],'Epsilon',0.1) || ...
                   tc.same(abs(t.sparse_dict(:,2)),[1;0],'Epsilon',0.1) || ...
                   tc.same(abs(t.sparse_dict(:,3)),[1;0],'Epsilon',0.1) || ...
                   tc.same(abs(t.sparse_dict(:,4)),[1;0],'Epsilon',0.1));
            assert(tc.same(abs(t.sparse_dict(:,1)),[0;1],'Epsilon',0.1) || ...
                   tc.same(abs(t.sparse_dict(:,2)),[0;1],'Epsilon',0.1) || ...
                   tc.same(abs(t.sparse_dict(:,3)),[0;1],'Epsilon',0.1) || ...
                   tc.same(abs(t.sparse_dict(:,4)),[0;1],'Epsilon',0.1));
            assert(tc.same(abs(t.sparse_dict(:,1)),[0.7071;0.7071],'Epsilon',0.1) || ...
                   tc.same(abs(t.sparse_dict(:,2)),[0.7071;0.7071],'Epsilon',0.1) || ...
                   tc.same(abs(t.sparse_dict(:,3)),[0.7071;0.7071],'Epsilon',0.1) || ...
                   tc.same(abs(t.sparse_dict(:,4)),[0.7071;0.7071],'Epsilon',0.1));
            assert(t.word_count == 4);
            assert(t.coeffs_count == 1);
            assert(t.initial_learning_rate == 0.1);
            assert(t.final_learning_rate == 0.01);
            assert(t.max_iter_count == 1000);
            assert(length(t.one_sample_plain.classes) == 1);
            assert(strcmp(t.one_sample_plain.classes{1},'none'));
            assert(t.one_sample_plain.classes_count == 1);
            assert(tc.check(t.one_sample_plain.samples == A(1,:)));
            assert(tc.check(t.one_sample_plain.labels_idx == c(1)));
            assert(t.one_sample_plain.samples_count == 1);
            assert(t.one_sample_plain.features_count == 2);
            assert(t.one_sample_plain.compatible(s));
            assert(length(t.one_sample_coded.classes) == 1);
            assert(strcmp(t.one_sample_coded.classes{1},'none'));
            assert(t.one_sample_coded.classes_count == 1);
            assert(tc.check(size(t.one_sample_coded.samples) == [1 4]));
            assert(tc.matrix(t.one_sample_coded.samples) && tc.number(t.one_sample_coded.samples));
            assert(tc.check(t.one_sample_coded.labels_idx == c(1)));
            assert(t.one_sample_coded.samples_count == 1);
            assert(t.one_sample_coded.features_count == 4);
            
            assert(tc.same(hnd.logged_data,sprintf(strcat('Learning sparse dictionary:\n',...
                                                          '  Building initial dictionary.\n',...
                                                          '  Tracking progress:\n',...
                                                          '    Iterations 1 to 50.\n',...
                                                          '    Iterations 51 to 100.\n',...
                                                          '    Iterations 101 to 150.\n',...
                                                          '    Iterations 151 to 200.\n',...
                                                          '    Iterations 201 to 250.\n',...
                                                          '    Iterations 251 to 300.\n',...
                                                          '    Iterations 301 to 350.\n',...
                                                          '    Iterations 351 to 400.\n',...
                                                          '    Iterations 401 to 450.\n',...
                                                          '    Iterations 451 to 500.\n',...
                                                          '    Iterations 501 to 550.\n',...
                                                          '    Iterations 551 to 600.\n',...
                                                          '    Iterations 601 to 650.\n',...
                                                          '    Iterations 651 to 700.\n',...
                                                          '    Iterations 701 to 750.\n',...
                                                          '    Iterations 751 to 800.\n',...
                                                          '    Iterations 801 to 850.\n',...
                                                          '    Iterations 851 to 900.\n',...
                                                          '    Iterations 901 to 950.\n',...
                                                          '    Iterations 951 to 1000.\n',...
                                                          'Extracting plain/coded samples:\n',...
                                                          '  Building sparse samples:\n',...
                                                          '    Processing samples 1 to 1.\n',...
                                                          '  Building dataset.\n'))));
            
            log.close();
            hnd.close();
            
            clearvars -except display;
            
            fprintf('  Function "code".\n');
            
            hnd = logging.handlers.testing(logging.level.All);
            log = logging.logger({hnd});
            A = [mvnrnd([0 0],[3 0; 0 0.01],200);mvnrnd([ 0 0],[0.01 0; 0 3],200);mvnrnd([0 0],[2 1.95; 1.95 2],200)];
            c = ones(600,1);            
            s = dataset({'none'},A,c);
            
            t = transforms.sparse.sgdmp(s,3,1,0.1,0.01,1000,log);            
            s_p = t.code(s,log);
            
            assert(tc.same(s_p.classes,s.classes));
            assert(s_p.classes_count == 1);
            assert(tc.matrix(s_p.samples));
            assert(tc.check(size(s_p.samples) == [600 3]));
            assert(tc.number(s_p.samples));
            assert(tc.check(s_p.labels_idx == s.labels_idx));
            assert(s_p.samples_count == 600);
            assert(s_p.features_count == 3);
            
            assert(tc.same(hnd.logged_data,sprintf(strcat('Learning sparse dictionary:\n',...
                                                          '  Building initial dictionary.\n',...
                                                          '  Tracking progress:\n',...
                                                          '    Iterations 1 to 50.\n',...
                                                          '    Iterations 51 to 100.\n',...
                                                          '    Iterations 101 to 150.\n',...
                                                          '    Iterations 151 to 200.\n',...
                                                          '    Iterations 201 to 250.\n',...
                                                          '    Iterations 251 to 300.\n',...
                                                          '    Iterations 301 to 350.\n',...
                                                          '    Iterations 351 to 400.\n',...
                                                          '    Iterations 401 to 450.\n',...
                                                          '    Iterations 451 to 500.\n',...
                                                          '    Iterations 501 to 550.\n',...
                                                          '    Iterations 551 to 600.\n',...
                                                          '    Iterations 601 to 650.\n',...
                                                          '    Iterations 651 to 700.\n',...
                                                          '    Iterations 701 to 750.\n',...
                                                          '    Iterations 751 to 800.\n',...
                                                          '    Iterations 801 to 850.\n',...
                                                          '    Iterations 851 to 900.\n',...
                                                          '    Iterations 901 to 950.\n',...
                                                          '    Iterations 951 to 1000.\n',...
                                                          'Extracting plain/coded samples:\n',...
                                                          '  Building sparse samples:\n',...
                                                          '    Processing samples 1 to 1.\n',...
                                                          '  Building dataset.\n',...
                                                          'Building sparse samples:\n',...
                                                          '  Processing samples 1 to 60.\n',...
                                                          '  Processing samples 61 to 120.\n',...
                                                          '  Processing samples 121 to 180.\n',...
                                                          '  Processing samples 181 to 240.\n',...
                                                          '  Processing samples 241 to 300.\n',...
                                                          '  Processing samples 301 to 360.\n',...
                                                          '  Processing samples 361 to 420.\n',...
                                                          '  Processing samples 421 to 480.\n',...
                                                          '  Processing samples 481 to 540.\n',...
                                                          '  Processing samples 541 to 600.\n',...
                                                          'Building dataset.\n'))));
            
            if exist('display','var') && (display == true)
                figure;
                subplot(1,2,1);
                hold on;
                scatter(s.samples(:,1),s.samples(:,2),'o','b');
                line([0;t.sparse_dict(1,1)],[0;t.sparse_dict(2,1)],'Color','r','LineWidth',3);
                line([0;t.sparse_dict(1,2)],[0;t.sparse_dict(2,2)],'Color','r','LineWidth',3);
                line([0;t.sparse_dict(1,3)],[0;t.sparse_dict(2,3)],'Color','r','LineWidth',3);
                title('Original samples.');
                hold off;
                subplot(1,2,2);
                scatter3(s_p.samples(:,1),s_p.samples(:,2),s_p.samples(:,3),'o','b');
                title('SGDMP transformed samples.');
                pause(5);
                close(gcf());
            end
            
            log.close();
            hnd.close();
            
            clearvars -except display;
            
            fprintf('  Function "decode".\n');
            
            fprintf('    With one kept coefficient.\n');
            
            hnd = logging.handlers.testing(logging.level.All);
            log = logging.logger({hnd});
            A = [mvnrnd([0 0],[3 0; 0 0.01],200);mvnrnd([ 0 0],[0.01 0; 0 3],200);mvnrnd([0 0],[2 1.95; 1.95 2],200)];
            c = ones(600,1);            
            s = dataset({'none'},A,c);
            
            t = transforms.sparse.sgdmp(s,3,1,0.1,0.01,1000,log);            
            s_p = t.code(s,log);
            s_r = t.decode(s_p,log);
            
            assert(tc.same(s_r.classes,s.classes));
            assert(s_r.classes_count == 1);
            assert(tc.check(s_r.samples == s_p.samples * t.sparse_dict'));
            assert(tc.check(s_r.labels_idx == s.labels_idx));
            assert(s_r.samples_count == 600);
            assert(s_r.features_count == 2);
            
            assert(tc.same(hnd.logged_data,sprintf(strcat('Learning sparse dictionary:\n',...
                                                          '  Building initial dictionary.\n',...
                                                          '  Tracking progress:\n',...
                                                          '    Iterations 1 to 50.\n',...
                                                          '    Iterations 51 to 100.\n',...
                                                          '    Iterations 101 to 150.\n',...
                                                          '    Iterations 151 to 200.\n',...
                                                          '    Iterations 201 to 250.\n',...
                                                          '    Iterations 251 to 300.\n',...
                                                          '    Iterations 301 to 350.\n',...
                                                          '    Iterations 351 to 400.\n',...
                                                          '    Iterations 401 to 450.\n',...
                                                          '    Iterations 451 to 500.\n',...
                                                          '    Iterations 501 to 550.\n',...
                                                          '    Iterations 551 to 600.\n',...
                                                          '    Iterations 601 to 650.\n',...
                                                          '    Iterations 651 to 700.\n',...
                                                          '    Iterations 701 to 750.\n',...
                                                          '    Iterations 751 to 800.\n',...
                                                          '    Iterations 801 to 850.\n',...
                                                          '    Iterations 851 to 900.\n',...
                                                          '    Iterations 901 to 950.\n',...
                                                          '    Iterations 951 to 1000.\n',...
                                                          'Extracting plain/coded samples:\n',...
                                                          '  Building sparse samples:\n',...
                                                          '    Processing samples 1 to 1.\n',...
                                                          '  Building dataset.\n',...
                                                          'Building sparse samples:\n',...
                                                          '  Processing samples 1 to 60.\n',...
                                                          '  Processing samples 61 to 120.\n',...
                                                          '  Processing samples 121 to 180.\n',...
                                                          '  Processing samples 181 to 240.\n',...
                                                          '  Processing samples 241 to 300.\n',...
                                                          '  Processing samples 301 to 360.\n',...
                                                          '  Processing samples 361 to 420.\n',...
                                                          '  Processing samples 421 to 480.\n',...
                                                          '  Processing samples 481 to 540.\n',...
                                                          '  Processing samples 541 to 600.\n',...
                                                          'Building dataset.\n',...
                                                          'Restoring original samples from sparse ones:\n',...
                                                          '  Processing samples 1 to 60.\n',...
                                                          '  Processing samples 61 to 120.\n',...
                                                          '  Processing samples 121 to 180.\n',...
                                                          '  Processing samples 181 to 240.\n',...
                                                          '  Processing samples 241 to 300.\n',...
                                                          '  Processing samples 301 to 360.\n',...
                                                          '  Processing samples 361 to 420.\n',...
                                                          '  Processing samples 421 to 480.\n',...
                                                          '  Processing samples 481 to 540.\n',...
                                                          '  Processing samples 541 to 600.\n',...
                                                          'Building dataset.\n'))));
            
            if exist('display','var') && (display == true)
                figure;
                subplot(1,3,1);
                hold on;
                scatter(s.samples(:,1),s.samples(:,2),'o','b');
                line([0;t.sparse_dict(1,1)],[0;t.sparse_dict(2,1)],'Color','r','LineWidth',3);
                line([0;t.sparse_dict(1,2)],[0;t.sparse_dict(2,2)],'Color','r','LineWidth',3);
                line([0;t.sparse_dict(1,3)],[0;t.sparse_dict(2,3)],'Color','r','LineWidth',3);
                title('Original samples.');
                hold off;
                subplot(1,3,2);
                scatter3(s_p.samples(:,1),s_p.samples(:,2),s_p.samples(:,3),'o','b');
                title('SGDMP transformed samples.');
                subplot(1,3,3);
                scatter(s_r.samples(:,1),s_r.samples(:,2),'o','b');
                title('Restored samples.');
                pause(5);
                close(gcf());
            end
            
            log.close();
            hnd.close();
            
            clearvars -except display;
            
            fprintf('    With 2 kept coefficients.\n');
            
            hnd = logging.handlers.testing(logging.level.All);
            log = logging.logger({hnd});
            A = [mvnrnd([0 0],[3 0; 0 0.01],200);mvnrnd([ 0 0],[0.01 0; 0 3],200);mvnrnd([0 0],[2 1.95; 1.95 2],200)];
            c = ones(600,1);            
            s = dataset({'none'},A,c);
            
            t = transforms.sparse.sgdmp(s,3,2,0.1,0.01,1000,log);
            s_p = t.code(s,log);
            s_r = t.decode(s_p,log);
            
            assert(tc.same(s_r.classes,s.classes));
            assert(s_r.classes_count == 1);
            assert(tc.check(s_r.samples == s_p.samples * t.sparse_dict'));
            assert(tc.check(s_r.labels_idx == s.labels_idx));
            assert(s_r.samples_count == 600);
            assert(s_r.features_count == 2);
            
            assert(tc.same(hnd.logged_data,sprintf(strcat('Learning sparse dictionary:\n',...
                                                          '  Building initial dictionary.\n',...
                                                          '  Tracking progress:\n',...
                                                          '    Iterations 1 to 50.\n',...
                                                          '    Iterations 51 to 100.\n',...
                                                          '    Iterations 101 to 150.\n',...
                                                          '    Iterations 151 to 200.\n',...
                                                          '    Iterations 201 to 250.\n',...
                                                          '    Iterations 251 to 300.\n',...
                                                          '    Iterations 301 to 350.\n',...
                                                          '    Iterations 351 to 400.\n',...
                                                          '    Iterations 401 to 450.\n',...
                                                          '    Iterations 451 to 500.\n',...
                                                          '    Iterations 501 to 550.\n',...
                                                          '    Iterations 551 to 600.\n',...
                                                          '    Iterations 601 to 650.\n',...
                                                          '    Iterations 651 to 700.\n',...
                                                          '    Iterations 701 to 750.\n',...
                                                          '    Iterations 751 to 800.\n',...
                                                          '    Iterations 801 to 850.\n',...
                                                          '    Iterations 851 to 900.\n',...
                                                          '    Iterations 901 to 950.\n',...
                                                          '    Iterations 951 to 1000.\n',...
                                                          'Extracting plain/coded samples:\n',...
                                                          '  Building sparse samples:\n',...
                                                          '    Processing samples 1 to 1.\n',...
                                                          '  Building dataset.\n',...
                                                          'Building sparse samples:\n',...
                                                          '  Processing samples 1 to 60.\n',...
                                                          '  Processing samples 61 to 120.\n',...
                                                          '  Processing samples 121 to 180.\n',...
                                                          '  Processing samples 181 to 240.\n',...
                                                          '  Processing samples 241 to 300.\n',...
                                                          '  Processing samples 301 to 360.\n',...
                                                          '  Processing samples 361 to 420.\n',...
                                                          '  Processing samples 421 to 480.\n',...
                                                          '  Processing samples 481 to 540.\n',...
                                                          '  Processing samples 541 to 600.\n',...
                                                          'Building dataset.\n',...
                                                          'Restoring original samples from sparse ones:\n',...
                                                          '  Processing samples 1 to 60.\n',...
                                                          '  Processing samples 61 to 120.\n',...
                                                          '  Processing samples 121 to 180.\n',...
                                                          '  Processing samples 181 to 240.\n',...
                                                          '  Processing samples 241 to 300.\n',...
                                                          '  Processing samples 301 to 360.\n',...
                                                          '  Processing samples 361 to 420.\n',...
                                                          '  Processing samples 421 to 480.\n',...
                                                          '  Processing samples 481 to 540.\n',...
                                                          '  Processing samples 541 to 600.\n',...
                                                          'Building dataset.\n'))));
            
            if exist('display','var') && (display == true)
                figure;
                subplot(1,3,1);
                hold on;
                scatter(s.samples(:,1),s.samples(:,2),'o','b');
                line([0;t.sparse_dict(1,1)],[0;t.sparse_dict(2,1)],'Color','r','LineWidth',3);
                line([0;t.sparse_dict(1,2)],[0;t.sparse_dict(2,2)],'Color','r','LineWidth',3);
                line([0;t.sparse_dict(1,3)],[0;t.sparse_dict(2,3)],'Color','r','LineWidth',3);
                title('Original samples.');
                hold off;
                subplot(1,3,2);
                scatter3(s_p.samples(:,1),s_p.samples(:,2),s_p.samples(:,3),'o','b');
                title('SGDMP transformed samples.');
                subplot(1,3,3);
                scatter(s_r.samples(:,1),s_r.samples(:,2),'o','b');
                title('Restored samples.');
                pause(5);
                close(gcf());
            end
            
            log.close();
            hnd.close();
            
            clearvars -except display;
        end
    end
end
